# main.py
# Punto de entrada principal. Orquesta solo la fase de b√∫squeda, an√°lisis y guardado de fuentes.

import scraper

# Importamos los m√≥dulos necesarios
import database

# analyzer y llm_client son usados internamente por scraper y analyzer,
# no necesitan importarse aqu√≠ directamente para la estructura deseada.

if __name__ == "__main__":
    # Inicializar la base de datos - LLAMA A LA FUNCI√ìN QUE CARGA schema.sql
    # Esto asegurar√° que las tablas existan.
    database.inicializar_db()

    # Definir los temas para buscar fuentes
    # Puedes cambiar este tema si ya tienes muchas fuentes sobre √©l
    temas = ["ultimas noticias sobre la guerra en Ucrania"]
    # Ejemplo con otro tema: temas = ["tendencias en rob√≥tica educativa 2024"]s


    # Iterar sobre los temas
    for tema in temas:
        # --- FASE 1: Buscar y Analizar Fuentes ---
        print(f"\n--- Iniciando fase de b√∫squeda y an√°lisis de fuentes para '{tema}' ---")

        # El scraper busca noticias, las analiza con Gemini y retorna las metadata de las que pasaron el filtro (score >= 5)
        # Mantenemos el comportamiento original de buscar un m√°ximo de 5 resultados analizados
        resultados_analisis_scraping = scraper.buscar_noticias(tema, num_noticias=10)

        # === L√≥gica de Feedback si no hay resultados analizados ===
        if not resultados_analisis_scraping:
            print(f"‚ö†Ô∏è No se encontraron art√≠culos fuente relevantes (score >= 5) para '{tema}' en esta ejecuci√≥n.")
            print("Esto puede deberse a que las fuentes encontradas ya estaban en la base de datos, no cumplieron el criterio de score/contenido, o hubo errores de acceso.")
            print("No se guardar√° ninguna fuente en esta ejecuci√≥n para este tema.")
            continue # Saltar al siguiente tema o terminar si solo hay uno
        # === FIN L√≥gica de Feedback ===


        # Imprimir los resultados analizados que se considerar√°n para guardar
        # Mantenemos la impresi√≥n original del TOP 3 de los resultados analizados encontrados
        print(f"\nüèÜ TOP {min(len(resultados_analisis_scraping), 3)} resultados analizados con Score >= 5 (se intentar√°n guardar como fuentes):")

        # Iterar sobre los primeros 3 resultados analizados para imprimir y guardar
        # El .get() para score, reason, url, tags y resumen se usa para mayor seguridad, aunque tu original usaba [] para algunos.
        # Mantengo la l√≥gica de iterar solo sobre los 3 primeros analizados (resultados_analisis_scraping[:3])
        for i, art in enumerate(resultados_analisis_scraping[:3], 1):
            print(f"\n{i}. ‚≠ê {art.get('score', 'N/A')}/10: {art.get('reason', 'Sin raz√≥n')}")
            print(f"   üîó {art.get('url', 'Sin URL')}")
            resumen_texto = art.get('resumen', art.get('reason', 'Sin resumen'))
            print(f"   üìù Resumen: {resumen_texto}")
            print(f"   üè∑Ô∏è Tags: {', '.join(art.get('tags', []))}")

            # Preparar el diccionario del art√≠culo para guardar en la tabla 'articulos'
            # Esta funci√≥n guarda en la tabla 'articulos' y 'articulos_fuente_tags'.
            # Asumimos que guardar_articulo ahora tambi√©n maneja el campo 'usada_para_generar' (con default 0)
            # y retorna el ID del art√≠culo fuente guardado o existente.
            articulo_db_source_data = {
                'titulo': art.get('titulo', f"Art√≠culo sobre {tema}"), # L√≥gica similar a la original
                'url': art.get('url', 'Sin URL'), # Usando .get por seguridad
                'score': art.get('score', 0), # Usando .get por seguridad
                'resumen': art.get('resumen', art.get('reason', '')[:100]), # L√≥gica original para resumen
                'fuente': art.get('url', '').split('/')[2] if art.get('url') else '',
                'tags': art.get('tags', []) # Usando .get
                # 'usada_para_generar' no se pasa aqu√≠; se espera que save_articulo la inserte con DEFAULT 0
            }

            # Guardar el art√≠culo fuente en la base de datos
            try:
                # guardar_articulo ahora retorna el ID del art√≠culo fuente guardado o existente
                source_id_saved = database.guardar_articulo(articulo_db_source_data)
                if source_id_saved:
                    print(f"   - Guardado/Actualizado como fuente en DB con ID {source_id_saved}.")
                else:
                     # Esto podr√≠a ocurrir si guardar_articulo retorna None por alg√∫n fallo interno
                     print(f"   - ‚ö†Ô∏è Fall√≥ el guardado o no se pudo obtener ID para fuente: {articulo_db_source_data.get('url', 'N/A')}")

            except Exception as e:
                # El manejo de error original solo imprime y contin√∫a. Lo replicamos.
                print(f"‚ö†Ô∏è Fall√≥ el guardado del art√≠culo fuente {articulo_db_source_data.get('url', 'N/A')}: {str(e)}")
                pass # Contin√∫a con el siguiente art√≠culo fuente aunque falle uno

        print("\n‚úÖ Fase de b√∫squeda, an√°lisis y guardado de fuentes completada.")

    # Mensaje final - Copiado exacto del original (aunque ahora solo guarda fuentes)
    print("\n‚úÖ Proceso principal completado (solo b√∫squeda y guardado de fuentes).")